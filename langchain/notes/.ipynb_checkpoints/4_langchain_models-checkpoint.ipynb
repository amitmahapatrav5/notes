{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d320dca2",
   "metadata": {},
   "source": [
    "# LangChain Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2e267-ce99-4dcd-9ade-8fe9e727a6bf",
   "metadata": {},
   "source": [
    "## Need of LangChain Model Component\n",
    "\n",
    "- We have various LLM Providers(OpenAI, Google, Anthropic etc), and interaction with each provider's model via api is different.\n",
    "- Langchain's Model component provides a common interface using which we can connect with any of these LLM Providers.\n",
    "\n",
    "## Types of LangChain Model\n",
    "\n",
    "1. Language Model (Text -> Text)\n",
    "   - LLM\n",
    "   - Chat Model\n",
    "2. Embedding Model (Text -> Vector)\n",
    "\n",
    "## Language Model (LLM vs Chat Model)\n",
    "\n",
    "### LLM\n",
    "\n",
    "- LLM Models are general Purpose models. You can use them for _Text Generation_, _Summarization_, _Code Generation_ etc\n",
    "- These Models take raw text as input and raw text as output\n",
    "- Legacy Models. Not used anymore.\n",
    "- **How these are trained:** General text Corpora(books and wikipedia data etc)\n",
    "- **Memory & Context:** No built-in Memory Support\n",
    "- **Role Awareness:** No understanding of roles.\n",
    "- **Example Models:** GPT-3, Llama-2.7B, Mistral-7B etc\n",
    "\n",
    "### Chat Models\n",
    "\n",
    "- Specialized for Conversational Task\n",
    "- Takes a sequence of Messages as input and Chat Messages(this is not plain text) as output.\n",
    "- Newer Model\n",
    "- **How these are trained:** After Base Models(LLMs) are prepared, they are fine-tuned on _Chat Dataset_(like dialogues, conversations etc)\n",
    "- **Memory & Context:** Supports Structured Conversation History\n",
    "- **Role Awareness:** Understands 'system', 'user' and 'assistant' roles.\n",
    "- **Example Models:** GPT-3.5-turbo, GPT-4, Llama-2-Chat, Mistral-Instruct etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5238ae-4dfa-44bd-b959-4561c46598d8",
   "metadata": {},
   "source": [
    "## Implementation - LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct')\n",
    "# NOTE: We are not passing API key explicitly.\n",
    "# Because the constructor will automatically fetch the API key from environment.\n",
    "# Provided the key is stored against a specific key name\n",
    "# In this case that is OPENAI_API_KEY\n",
    "\n",
    "result = llm.invoke('What is the capital of India?') # This is a raw text\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b2aff-7d56-4c63-86f6-d2dd4e08e767",
   "metadata": {},
   "source": [
    "**temperature param: When temperature=0, then for the given input, LLM is going to generate the same output all the time**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811acc29",
   "metadata": {},
   "source": [
    "## Implementation - OpenAI - Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf138ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OPENAI_API_KEY\n",
    "model = ChatOpenAI(model='gpt-4', max_completion_tokens=10)\n",
    "\n",
    "result = model.invoke('What is the capital of India?')\n",
    "\n",
    "print(result) # This is not a plane text\n",
    "print( result.content )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875709c",
   "metadata": {},
   "source": [
    "## Implementation - HuggingFace - API - Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# HUGGINGFACEHUB_API_TOKEN\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='',\n",
    "    task='text-generation'\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke('What is the capital of India?')\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c18855",
   "metadata": {},
   "source": [
    "## Implementation - HuggingFace - Local - Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef48273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    repo_id='',\n",
    "    task='text-generation'\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke('What is the capital of India?')\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b63cd",
   "metadata": {},
   "source": [
    "## Implementation - OpenAI - Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='')\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Sachin Tendulkar, often called the God of Cricket, holds the record for the most runs in both Test and ODI formats and is the only player to score 100 international centuries.\",\n",
    "        metadata={\n",
    "            'sport': 'cricket'\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cristiano Ronaldo is widely regarded as one of the greatest footballers ever, with over 790 career goals and multiple Ballon d'Or awards, showcasing his dominance across clubs and countries.\",\n",
    "        metadata={\n",
    "            'sport': 'football'\n",
    "        }\n",
    "    )\n",
    "]\n",
    "embeddings = embedding_model.embed_documents([ doc.page_content for doc in docs ], chunk_size=500)\n",
    "\n",
    "embedding_model.embed_query(docs[0].page_content)\n",
    "\n",
    "print(len(embeddings))\n",
    "for embedding in embeddings:\n",
    "    print(embedding, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c8883-69a6-4e9d-9b47-47e0dedeaa77",
   "metadata": {},
   "source": [
    "## Implementation - HuggingFace - API - Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b9625",
   "metadata": {},
   "source": [
    "## Implementation - HuggingFace - Local - Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2bafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model='')\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Sachin Tendulkar, often called the God of Cricket, holds the record for the most runs in both Test and ODI formats and is the only player to score 100 international centuries.\",\n",
    "        metadata={\n",
    "            'sport': 'cricket'\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cristiano Ronaldo is widely regarded as one of the greatest footballers ever, with over 790 career goals and multiple Ballon d'Or awards, showcasing his dominance across clubs and countries.\",\n",
    "        metadata={\n",
    "            'sport': 'football'\n",
    "        }\n",
    "    )\n",
    "]\n",
    "embeddings = embedding_model.embed_documents([ doc.page_content for doc in docs ], chunk_size=500)\n",
    "\n",
    "embedding_model.embed_query(docs[0].page_content)\n",
    "\n",
    "print(len(embeddings))\n",
    "for embedding in embeddings:\n",
    "    print(embedding, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
