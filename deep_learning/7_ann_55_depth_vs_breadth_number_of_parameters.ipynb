{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933cbbe7",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 7 \\\n",
    "Lecture: 55 \\\n",
    "Title: Depth vs. breadth: number of parameters \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27842154 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# Depth vs Breadth Number Of Parameters\n",
    "\n",
    "## Breadth vs Depth of ANN\n",
    "\n",
    "Depth is the number of hidden layers (layers between input and output)\n",
    "\n",
    "Breadth/width is the number of units per hidden layer(can vary across layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee37886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNWide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNWide, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.Linear(4, 3)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.stack(X)\n",
    "\n",
    "ANNWide()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94018392",
   "metadata": {},
   "source": [
    "    ANNWide(\n",
    "      (stack): Sequential(\n",
    "        (0): Linear(in_features=2, out_features=4, bias=True)\n",
    "        (1): Linear(in_features=4, out_features=3, bias=True)\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNDeep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNDeep, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, 2),\n",
    "            nn.Linear(2, 2),\n",
    "            nn.Linear(2, 3)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.stack(X)\n",
    "\n",
    "ANNDeep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84de06",
   "metadata": {},
   "source": [
    "    ANNDeep(\n",
    "      (stack): Sequential(\n",
    "        (0): Linear(in_features=2, out_features=2, bias=True)\n",
    "        (1): Linear(in_features=2, out_features=2, bias=True)\n",
    "        (2): Linear(in_features=2, out_features=3, bias=True)\n",
    "      )\n",
    "    )\n",
    "\n",
    "### Counting number of Nodes/Units in ANN [`.named_parameters()`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# named_parameters() is an iterable that returns the tuple (name,numbers)\n",
    "\n",
    "n_ann_wide_nodes = 0\n",
    "for param_name, param_weights in ANNWide().named_parameters():\n",
    "    # print(param_name, end='\\n\\n')\n",
    "    # print(param_tensor, end='\\n\\n')\n",
    "    if 'bias' in param_name:\n",
    "        n_ann_wide_nodes += len(param_weights)\n",
    "\n",
    "n_ann_deep_nodes = 0\n",
    "for param_name, param_weights in ANNDeep().named_parameters():\n",
    "    if 'bias' in param_name:\n",
    "        n_ann_deep_nodes += len(param_weights)\n",
    "\n",
    "\n",
    "# In both the cases, we are not considering the nodes in input layer\n",
    "print(f'Number of nodes in ANNWide is {n_ann_wide_nodes}')\n",
    "print(f'Number of nodes in ANNDeep is {n_ann_deep_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33d2dd",
   "metadata": {},
   "source": [
    "    Number of nodes in ANNWide is 7\n",
    "    Number of nodes in ANNDeep is 7\n",
    "\n",
    "### Counting number of Trainable Parameters in ANN [`.numel()`, `.parameters()`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681da774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, we pass ANNWide().parameters in optimizer constructor\n",
    "n_ann_wide_trained_param = 0\n",
    "for param in ANNWide().parameters():\n",
    "    # print(param)\n",
    "    # print(param.requires_grad)\n",
    "    n_ann_wide_trained_param += param.numel()\n",
    "\n",
    "n_ann_deep_trained_param = 0\n",
    "for param in ANNDeep().parameters():\n",
    "    # print(param)\n",
    "    # print(param.requires_grad)\n",
    "    n_ann_deep_trained_param += param.numel()\n",
    "\n",
    "print(f'Number of trainable parameters in ANNWide is {n_ann_wide_trained_param}')\n",
    "print(f'Number of trainable parameters in ANNDeep is {n_ann_deep_trained_param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5074d9",
   "metadata": {},
   "source": [
    "    Number of trainable parameters in ANNWide is 27\n",
    "    Number of trainable parameters in ANNDeep is 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(ANNWide, (1,2))\n",
    "# this is supposed to work, but not sure why it is not working"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
