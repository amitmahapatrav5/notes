{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25b4783",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 7 \\\n",
    "Lecture: 45 \\\n",
    "Title: ANN for regression \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27842126 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# ANN for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "size = 50\n",
    "\n",
    "x = torch.randn(size,1)\n",
    "y = x + torch.randn(size,1)/2\n",
    "# torch.randn(size,1)/2 is a noise. Why?, because it is not constant like y-intercept\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c87b9",
   "metadata": {},
   "source": [
    "    (torch.Size([50, 1]), torch.Size([50, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(x,y,'s', label='Training Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a40fa3",
   "metadata": {},
   "source": [
    "![png](7_ann_45_ann_for_regression_files/7_ann_45_ann_for_regression_4_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03516ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNRegression, self).__init__()\n",
    "        self. stack = nn.Sequential(\n",
    "            nn.Linear(1, 1)\n",
    "        )\n",
    "    def forward(self, data):\n",
    "        return self.stack(data)\n",
    "model = ANNRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "loss_func = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdde525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "losses = torch.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    yHat = model(x)\n",
    "\n",
    "    loss = loss_func(y, yHat)\n",
    "    losses[epoch] = loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7764c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure Model Performance\n",
    "prediction = model(x)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axes[0].plot(x, y, 's', color='b', label='Training Data')\n",
    "axes[0].plot(x, prediction.detach(), 'o', color='g', label='Model Prediction')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('y')\n",
    "axes[0].set_title('Reality vs Prediction')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].scatter(range(epochs), losses.detach(), color='b')\n",
    "axes[1].set_xlabel('epochs')\n",
    "axes[1].set_ylabel('cost')\n",
    "axes[1].set_title('Loss Per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45d24c",
   "metadata": {},
   "source": [
    "![png](7_ann_45_ann_for_regression_files/7_ann_45_ann_for_regression_8_0.png)\n",
    "\n",
    "### If DL is so great, why don't we all switch to DL models instead of traditional statistical models?\n",
    "\n",
    "Traditional statistical models tend to work better on smaller datasets, are better mathematically characterize (e.g. guaranteed optimal solutions) and are more interpretable. But DL models, does not provide any guarantee the optimal solution, but proceed towards a good solution."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
