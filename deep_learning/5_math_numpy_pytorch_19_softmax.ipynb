{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a83a4b",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 5 \\\n",
    "Lecture: 19 \\\n",
    "Title: Softmax \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27841936 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# Softmax\n",
    "\n",
    "### Softmax Function Definition\n",
    "\n",
    "The softmax function is defined as:\n",
    "\n",
    "$\n",
    "\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\quad \\text{for } i = 1, \\ldots, K\n",
    "$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $ z $ is a vector of raw scores (logits)\n",
    "- $ K $ is the number of classes\n",
    "- $ \\sigma(z_i) $ is the probability of the $ i $-th class\n",
    "\n",
    "### Softmax Example for $ Z = \\{1, 2, 3\\} $\n",
    "\n",
    "1. **Input Vector**:\n",
    "   $$Z = \\{1, 2, 3\\}$$\n",
    "\n",
    "2. **Calculate Exponentials**:\n",
    "\n",
    "   - $ e^{1} \\approx 2.718 $\n",
    "   - $ e^{2} \\approx 7.389 $\n",
    "   - $ e^{3} \\approx 20.085 $\n",
    "\n",
    "3. **Sum of Exponentials**:\n",
    "   $$\\text{Sum} = e^{1} + e^{2} + e^{3} \\approx 2.718 + 7.389 + 20.085 \\approx 30.192$$\n",
    "\n",
    "4. **Calculate Softmax Probabilities**:\n",
    "\n",
    "   - For $ z_1 = 1 $:\n",
    "     $$\\sigma(z_1) = \\frac{e^{1}}{\\text{Sum}} \\approx \\frac{2.718}{30.192} \\approx 0.0907$$\n",
    "   - For $ z_2 = 2 $:\n",
    "     $$\\sigma(z_2) = \\frac{e^{2}}{\\text{Sum}} \\approx \\frac{7.389}{30.192} \\approx 0.2447$$\n",
    "   - For $ z_3 = 3 $:\n",
    "     $$\\sigma(z_3) = \\frac{e^{3}}{\\text{Sum}} \\approx \\frac{20.085}{30.192} \\approx 0.6652$$\n",
    "\n",
    "5. **Softmax Output**:\n",
    "   $$\\sigma(Z) \\approx \\{0.0907, 0.2447, 0.6652\\}$$\n",
    "\n",
    "The outputs of the softmax function can be interpreted as probabilities since their sum always equals 1. However, it's important to note that these values do not necessarily represent true probabilities in all contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc825ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Z = [1, 2, 3]\n",
    "a, b, c = np.exp(Z[0]), np.exp(Z[1]), np.exp(Z[2])\n",
    "abc = a + b + c\n",
    "\n",
    "print( a/abc, b/abc, c/abc )\n",
    "np.sum([a/abc, b/abc, c/abc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "Z = torch.tensor([1, 2, 3])\n",
    "a, b, c = torch.exp(Z[0]), torch.exp(Z[1]), torch.exp(Z[2])\n",
    "abc = a + b + c\n",
    "\n",
    "print( a/abc, b/abc, c/abc )\n",
    "torch.sum(torch.tensor( [a/abc, b/abc, c/abc] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "Z = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "softmax(Z)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
