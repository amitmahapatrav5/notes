{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1677c42e",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 7 \\\n",
    "Lecture: 50 \\\n",
    "Title: Linear solutions to linear problems \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27842140 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# Linear Solution to Linear Problems\n",
    "\n",
    "## Demystifying the uncertainity to Qwerty's problem\n",
    "\n",
    "The problem we faced earlier was with one perceptron or multilayer perceptron, for the exact same metaparameters, the model was either performing poorly or very good. Why is this the case?\n",
    "\n",
    "It turns out that, Qwerty is a very simple binary classification problem. However to solve that, we are using non-linear model. So the model is trying to find a non-linear solution, whearase a simple linear line can solve the problem. So we can just remove the non-linearity(nn.ReLU activation fuctions) from the model and should give us consistent result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ab668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "A = [ 1, 1 ]\n",
    "B = [ 1, 5 ]\n",
    "N = 100\n",
    "\n",
    "a = torch.stack((A[0]+torch.randn(N), A[1]+torch.randn(N)), dim=1)\n",
    "b = torch.stack((B[0]+torch.randn(N), B[1]+torch.randn(N)), dim=1)\n",
    "\n",
    "data = torch.vstack((a, b))\n",
    "labels = torch.vstack((torch.zeros(N, 1), torch.ones(N, 1)))\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8b0ca",
   "metadata": {},
   "source": [
    "    (torch.Size([200, 2]), torch.Size([200, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "plt.scatter(data [torch.where(labels==0)[0], 0], data [torch.where(labels==0)[0], 1], marker='s', color='b', facecolor='w')\n",
    "plt.scatter(data [torch.where(labels==1)[0], 0], data [torch.where(labels==1)[0], 1], marker='s', color='g', facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af6548",
   "metadata": {},
   "source": [
    "![png](7_ann_50_linear_solutions_to_linear_problems_files/7_ann_50_linear_solutions_to_linear_problems_5_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b954b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "class ANNMultiLayerBinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNMultiLayerBinaryClassifier, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            # nn.ReLU(), # removed non-linearity\n",
    "            nn.Linear(16, 1),\n",
    "            # nn.ReLU(), # removed non-linearity\n",
    "            nn.Linear(1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.stack(X)\n",
    "\n",
    "ANNMultiLayerBinaryClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f1e7d",
   "metadata": {},
   "source": [
    "    ANNMultiLayerBinaryClassifier(\n",
    "      (stack): Sequential(\n",
    "        (0): Linear(in_features=2, out_features=16, bias=True)\n",
    "        (1): Linear(in_features=16, out_features=1, bias=True)\n",
    "        (2): Linear(in_features=1, out_features=1, bias=True)\n",
    "        (3): Sigmoid()\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49517f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 1000\n",
    "\n",
    "def train(lr):\n",
    "    model = ANNMultiLayerBinaryClassifier()\n",
    "    loss_func = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    losses = torch.zeros(epochs)\n",
    "    for epoch in range(epochs):\n",
    "        # forward\n",
    "        yHat = model(data)\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_func(yHat, labels)\n",
    "        losses[epoch] = loss\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    prediction = model(data)\n",
    "    accuracy = torch.mean(((prediction>0.5)==labels).float()) * 100\n",
    "\n",
    "    return accuracy, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the code ones\n",
    "accuracy, losses = train(lr=0.01)\n",
    "\n",
    "plt.plot(range(epochs), losses.detach(), marker='o')\n",
    "plt.title(f'Epoch vs Loss, accuracy={accuracy}')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172c8b1",
   "metadata": {},
   "source": [
    "![png](7_ann_50_linear_solutions_to_linear_problems_files/7_ann_50_linear_solutions_to_linear_problems_8_0.png)\n",
    "\n",
    "## Experiment Learning Rate vs Accuracy and Epochs vs Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe697ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = torch.linspace(0.001, 0.1, 40)\n",
    "\n",
    "allLosses = torch.zeros((len(lrs), epochs))\n",
    "accuracies = torch.zeros(len(lrs))\n",
    "\n",
    "for i in range(len(lrs)):\n",
    "    accuracy, losses = train(lrs[i])\n",
    "\n",
    "    allLosses[i, :] = losses\n",
    "    accuracies[i] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e60a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Experiment Findings\n",
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Learning Rate vs Accuracy\n",
    "axes[0].plot(lrs.detach(), accuracies.detach(), marker='s', linestyle='-', markerfacecolor='w')\n",
    "axes[0].set_xlabel('Learning Rate')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title(f'Accuracy(MAX={accuracies.max()}%, MIN={accuracies.min()}%) by Learning Rate')\n",
    "\n",
    "# Epochs vs Losses\n",
    "for i, lr in enumerate(lrs):\n",
    "    axes[1].plot(range(len(allLosses[i])), allLosses[i].detach(), linestyle='-')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Losses by Learning Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74aac8",
   "metadata": {},
   "source": [
    "![png](7_ann_50_linear_solutions_to_linear_problems_files/7_ann_50_linear_solutions_to_linear_problems_11_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712022f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
