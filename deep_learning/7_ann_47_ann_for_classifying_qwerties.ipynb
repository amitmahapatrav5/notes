{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de10bf9",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 7 \\\n",
    "Lecture: 47 \\\n",
    "Title: ANN for classifying qwerties \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27842130 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# ANN for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100159f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "N = 100\n",
    "A = [ 1, 1 ]\n",
    "B = [ 5, 1 ]\n",
    "\n",
    "a = torch.vstack( ( A[0] + torch.randn(N), A[1] + torch.randn(N) ) )\n",
    "b = torch.vstack( ( B[0] + torch.randn(N), B[1] + torch.randn(N) ) )\n",
    "\n",
    "data = torch.vstack( ( a.T, b.T ) )\n",
    "labels = torch.vstack( ( torch.zeros(N, 1), torch.ones(N, 1) ) )\n",
    "\n",
    "plt.scatter(data [ torch.where(labels==0)[0], 0 ], data [ torch.where(labels==0)[0], 1 ], marker='s', color='b', facecolor='w')\n",
    "plt.scatter(data [ torch.where(labels==1)[0], 0 ], data [ torch.where(labels==1)[0], 1 ], marker='s', color='g', facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2b997",
   "metadata": {},
   "source": [
    "![png](7_ann_47_ann_for_classifying_qwerties_files/7_ann_47_ann_for_classifying_qwerties_3_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0dc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "class ANNClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANNClassify, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "\n",
    "model = ANNClassify()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39bd85",
   "metadata": {},
   "source": [
    "    ANNClassify(\n",
    "      (stack): Sequential(\n",
    "        (0): Linear(in_features=2, out_features=1, bias=True)\n",
    "        (1): ReLU()\n",
    "        (2): Linear(in_features=1, out_features=1, bias=True)\n",
    "        (3): Sigmoid()\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metaparameter Set Up\n",
    "learning_rate = 0.01\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "epochs = 2000\n",
    "losses = torch.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # forward pass\n",
    "    yHat = model(data)\n",
    "\n",
    "    # Calculating Loss\n",
    "    loss = loss_func(yHat, labels)\n",
    "    losses[epoch] = loss\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model Performance\n",
    "prediction = model(data)\n",
    "\n",
    "prediction [ torch.where(prediction > 0.5) ] = 1.\n",
    "prediction [ torch.where(prediction <= 0.5) ] = 0.\n",
    "\n",
    "performance = torch.corrcoef ( torch.vstack( ( prediction.T, labels.T ) ) )[0, 1].detach()*100\n",
    "\n",
    "plt.scatter(data[ torch.where(labels == 1.)[0], 0 ], data[ torch.where(labels == 1.)[0], 1 ], marker='s', color='g', facecolor='w')\n",
    "plt.scatter(data[ torch.where(labels == 0.)[0], 0 ], data[ torch.where(labels == 0.)[0], 1 ], marker='s', color='b', facecolor='w')\n",
    "plt.scatter(data[ torch.where(prediction != labels)[0], 0 ], data[ torch.where(prediction != labels)[0], 1 ], marker='x', color='r')\n",
    "plt.title(f'Performance = {torch.round(performance)} %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fcd20a",
   "metadata": {},
   "source": [
    "![png](7_ann_47_ann_for_classifying_qwerties_files/7_ann_47_ann_for_classifying_qwerties_7_0.png)\n",
    "\n",
    "### Why ReLU is used in the internal layers but sigmoid in the output layer?\n",
    "\n",
    "ReLU is commonly used in the internal layers of a neural network because it helps to mitigate the vanishing gradient(**Need to knaow what is this**) problem.\n",
    "Sigmoid function is used in the output layer because it outputs values between 0 and 1, which is suitable for binary classification tasks.\n",
    "\n",
    "### Why BCELoss is used instead of MSELoss?\n",
    "\n",
    "This problem is a BCELoss problem. What does that mean?\n",
    "\n",
    "### How to interpret the loss function?\n",
    "\n",
    "If you can see here, with 1500 epochs, the curve has still not yet asymptoted. So the model can still learn. May be here we can increase the number of epochs or vary some other metaparameters to get to that phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b361794",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( range(1, epochs+1), losses.detach(), marker='o', markerfacecolor='w' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddfcc89",
   "metadata": {},
   "source": [
    "![png](7_ann_47_ann_for_classifying_qwerties_files/7_ann_47_ann_for_classifying_qwerties_11_0.png)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
