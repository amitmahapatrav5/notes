{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613fc7c3",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 7 \\\n",
    "Lecture: 43 \\\n",
    "Title: ANN math part 2 (errors, loss, cost) \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27842120 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# Loss Functions and Cost Function\n",
    "\n",
    "## Loss Function\n",
    "\n",
    "Most Commonly used Loss Functions are Mean Squared Error and Cross Entropy Error.\n",
    "There are lots of other errors, but majority are basically variations of these 2 types of Loss Function.\n",
    "\n",
    "**Mean Squared Error**\n",
    "\n",
    "- This error function is mainly used when the model predicts continuous data\n",
    "- Example: House Price Prediction, Temprature Prediction etc\n",
    "- $ L = \\frac{1}{2} ( \\hat{y} - y )^{2} $\n",
    "\n",
    "**Cross Entropy Error**\n",
    "\n",
    "- This error function is used when the model predicts probability\n",
    "- Example: Text Sentiment Classification, Digit Recognization etc\n",
    "- $ L = -( y _ log ({\\hat{y}}) + (1-y) _ log(1 - \\hat{y}) ) $\n",
    "\n",
    "## Loss Function Vs Cost Function\n",
    "\n",
    "- Cost Function is literally just the average of losses for all the training data.\n",
    "- We calculate the loss for every single data point using loss function. And cost function is just the average of all those losses.\n",
    "- $ C = \\frac{1}{n} \\sum\\_{i=1}^{n} L(\\hat{y}, y)$\n",
    "- The entire goal of deep learning is **find the weights such that it minimizes the cost function.**\n",
    "\n",
    "### Why train on cost but not loss\n",
    "\n",
    "- Training the model on each sample is time consuming and may lead to overfitting.\n",
    "- Also averaging over too many sample, may decrease the sensitivity.\n",
    "- The best approach is to train the model in \"batches\" of samples.\n",
    "\n",
    "#### Example\n",
    "\n",
    "- Say we have 2000 Samples in training data.\n",
    "- Calculating Loss for each sample and then chainging the weights will overfit the model\n",
    "- Calculating Cost from Loss of each sample and the changing the weights might decrease the sensitivity of the model\n",
    "- Best way is, create batches, each having say 20 samples and calculate the cost by averaging the loss of each sample in the batch and change the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d3ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6acc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
