{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e4c338",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 6 \\\n",
    "Lecture: 32 \\\n",
    "Title: Gradient descent in 1D \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27842084 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# Gradient Descent in 1D\n",
    "\n",
    "### Things to remember\n",
    "\n",
    "- Gradient Descent basically helps in finding out the approximate x, where y value is minimum.\n",
    "- It does that by the help of slope.\n",
    "- To visualize in 2D, when slope is positive, X is decreased and when slope is negetive X is increased.\n",
    "- It works in any dimension.\n",
    "- Drawback is, sometimes, it might get stuck in a local mimima. However this is not a big problem, because in higher dimension, the probability of getting stuck in a local mimima is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edba45",
   "metadata": {},
   "source": [
    "## Functions having single local minima\n",
    "\n",
    "$f(x)=x^2 - 12x +36$\n",
    "\n",
    "$dy/dx = 2x - 12$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac73a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x):\n",
    "    return x**2 - 12*x - 36\n",
    "\n",
    "def dydx(x):\n",
    "    return 2*x - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = (0, 12)\n",
    "X = np.arange(*domain, 0.005)\n",
    "Y = fx(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97010dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e61657",
   "metadata": {},
   "source": [
    "![png](6_gradient_descent_32_gradient_descent_in_1d_files/6_gradient_descent_32_gradient_descent_in_1d_8_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d680dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "localmin = np.random.choice(X, 1)\n",
    "learning = np.zeros((epochs, 2))\n",
    "for epoch in range(epochs):\n",
    "    grad = dydx(localmin)\n",
    "    learning[epoch][0] = localmin[0]\n",
    "    learning[epoch][1] = fx(localmin)[0]\n",
    "    localmin -= learning_rate*grad # ROOT OF GRADIENT DESCENT\n",
    "localmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cd933",
   "metadata": {},
   "source": [
    "    array([6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a802ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y= learning[:,0], learning[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bdbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, Y)\n",
    "plt.scatter(x, y, c='g', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9cbb4",
   "metadata": {},
   "source": [
    "![png](6_gradient_descent_32_gradient_descent_in_1d_files/6_gradient_descent_32_gradient_descent_in_1d_12_0.png)\n",
    "\n",
    "## What happens when we make the learning parameter too large or too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d00575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(localmin, learning_rate, epochs):\n",
    "    learning = np.zeros((epochs, 2))\n",
    "    for epoch in range(epochs):\n",
    "        grad = dydx(localmin)\n",
    "        learning[epoch][0] = localmin[0]\n",
    "        learning[epoch][1] = fx(localmin)[0]\n",
    "        localmin -= learning_rate*grad # ROOT OF GRADIENT DESCENT\n",
    "    return localmin, learning\n",
    "\n",
    "def plot(X, Y, x, y):\n",
    "    plt.plot(X, Y)\n",
    "    plt.scatter(x, y, c='g', marker='o')\n",
    "    plt.show()\n",
    "\n",
    "def fx(x):\n",
    "    return x**2 - 12*x - 36\n",
    "\n",
    "def dydx(x):\n",
    "    return 2*x - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0, 12, 0.005)\n",
    "Y = fx(X)\n",
    "plt.plot(X, Y)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80209723",
   "metadata": {},
   "source": [
    "    []\n",
    "\n",
    "![png](6_gradient_descent_32_gradient_descent_in_1d_files/6_gradient_descent_32_gradient_descent_in_1d_15_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32145704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will diverge\n",
    "localmin, learning = gradient_descent(np.array([0.]), learning_rate=1, epochs=100)\n",
    "plot(X, Y, learning[:, 0], learning[:, 1])\n",
    "localmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d1e17",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "![png](6_gradient_descent_32_gradient_descent_in_1d_files/6_gradient_descent_32_gradient_descent_in_1d_16_0.png)\n",
    "\n",
    "    array([0.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will converge\n",
    "localmin, learning = gradient_descent(np.array([0.]), learning_rate=0.1, epochs=100)\n",
    "plot(X, Y, learning[:, 0], learning[:, 1])\n",
    "localmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af03c0",
   "metadata": {},
   "source": [
    "![png](6_gradient_descent_32_gradient_descent_in_1d_files/6_gradient_descent_32_gradient_descent_in_1d_17_0.png)\n",
    "\n",
    "    array([6.])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
