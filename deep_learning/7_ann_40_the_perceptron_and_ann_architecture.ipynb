{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7bb9fb",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Section: 7 \\\n",
    "Lecture: 40 \\\n",
    "Title: The perceptron and ANN architecture \\\n",
    "TCS Udemy Reference Link: https://tcsglobal.udemy.com/course/deeplearning_x/learn/lecture/27842114 \\\n",
    "Udemy Reference Link: \\\n",
    "Pre-Requisite:\n",
    "\n",
    "# Linear and Non Linear ANN Model\n",
    "\n",
    "**Linear models only solve linearly separable problems** \\\n",
    "**Model is considered Linear, if the operation it is performing is only addition or multiplication** \\\n",
    "**If the Model is performing anything else, then it is Non-Linear Model** \\\n",
    "**I think the only component that can be non Linear is activation function**\n",
    "\n",
    "**We should not use Linear Models for Non Linear Problems** \\\n",
    "**Similarly, we should not use Non Linear Models for Linear Problems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a188266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef3472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Linear Model\n",
    "class  LinearANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearANN, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(3, 1)\n",
    "        )\n",
    "LinearANN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed6c52",
   "metadata": {},
   "source": [
    "    LinearANN(\n",
    "      (stack): Sequential(\n",
    "        (0): Linear(in_features=3, out_features=1, bias=True)\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b52949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Non-Linear Model\n",
    "class NonLinearANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NonLinearANN, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(3, 1),\n",
    "            nn.Sigmoid() # This is the non Linear Component\n",
    "        )\n",
    "NonLinearANN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865d92d",
   "metadata": {},
   "source": [
    "    NonLinearANN(\n",
    "      (stack): Sequential(\n",
    "        (0): Linear(in_features=3, out_features=1, bias=True)\n",
    "        (1): Sigmoid()\n",
    "      )\n",
    "    )\n",
    "\n",
    "**Linearly Separable problem: Where the separation can be performed by a line or plane or hyperplane**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf0354",
   "metadata": {},
   "source": [
    "**Majority math that happens in any ANN is $\\sigma(X^{T}W)$**\n",
    "\n",
    "**Why do we need bias?**\n",
    "\n",
    "Equations like $aX + bY + ... + cZ = 0$ always passes through origin. \\\n",
    "But equations like $aX + bY + ... + cZ + bias = 0$ does not, and hence the advantage as shown in below figure. \\\n",
    "However, it is possible to mean center all the points so that we will always have the separating hyper-plane pass through origin. But this is not something we always go for. I am not exactly clear on the scenario of non-linear equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nPerClust = 100\n",
    "blur = 1\n",
    "\n",
    "# First diagram coordinates\n",
    "A1 = [3, 8]\n",
    "B1 = [8, 3]\n",
    "\n",
    "# Second diagram coordinates (existing)\n",
    "A2 = [1, 1]\n",
    "B2 = [6, 6]\n",
    "\n",
    "# Generate data for the first diagram\n",
    "a1 = torch.stack((A1[0] + torch.randn(nPerClust) * blur, A1[1] + torch.randn(nPerClust) * blur))\n",
    "b1 = torch.stack((B1[0] + torch.randn(nPerClust) * blur, B1[1] + torch.randn(nPerClust) * blur))\n",
    "\n",
    "# Generate data for the second diagram\n",
    "a2 = torch.stack((A2[0] + torch.randn(nPerClust) * blur, A2[1] + torch.randn(nPerClust) * blur))\n",
    "b2 = torch.stack((B2[0] + torch.randn(nPerClust) * blur, B2[1] + torch.randn(nPerClust) * blur))\n",
    "\n",
    "# True labels for both diagrams\n",
    "labels1 = torch.cat((torch.zeros(nPerClust, 1), torch.ones(nPerClust, 1)))\n",
    "labels2 = torch.cat((torch.zeros(nPerClust, 1), torch.ones(nPerClust, 1)))\n",
    "\n",
    "# Concatenate into matrices\n",
    "data1 = torch.cat((a1, b1), dim=1).T\n",
    "data2 = torch.cat((a2, b2), dim=1).T\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# No Need of Bias for this\n",
    "axs[0].plot(data1[labels1.squeeze() == 0, 0], data1[labels1.squeeze() == 0, 1], 'bs', label='Cluster A')\n",
    "axs[0].plot(data1[labels1.squeeze() == 1, 0], data1[labels1.squeeze() == 1, 1], 'ko', label='Cluster B')\n",
    "axs[0].set_title('Separating Line Passes through Origin')\n",
    "axs[0].legend()\n",
    "\n",
    "# Need Bias for this\n",
    "axs[1].plot(data2[labels2.squeeze() == 0, 0], data2[labels2.squeeze() == 0, 1], 'bs', label='Cluster A')\n",
    "axs[1].plot(data2[labels2.squeeze() == 1, 0], data2[labels2.squeeze() == 1, 1], 'ko', label='Cluster B')\n",
    "axs[1].set_title('Separating Line cannot pass through Origin')\n",
    "axs[1].legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3542a",
   "metadata": {},
   "source": [
    "![png](7_ann_40_the_perceptron_and_ann_architecture_files/7_ann_40_the_perceptron_and_ann_architecture_10_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1377c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
